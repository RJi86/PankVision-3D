{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP13g6Rs0vZ8rARxGGJp5na"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# %%capture\n","# !pip install monai"],"metadata":{"id":"_EGURTLHju3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBiHjbEq7h3f"},"outputs":[],"source":["from monai.utils import first\n","import matplotlib.pyplot as plt\n","import torch\n","import os\n","import numpy as np\n","from monai.losses import DiceLoss\n","from tqdm import tqdm\n","\n","def dice_metric(predicted, target):\n","    '''\n","    In this function we take `predicted` and `target` (label) to calculate the dice coeficient then we use it\n","    to calculate a metric value for the training and the validation.\n","    '''\n","    dice_value = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n","    value = 1 - dice_value(predicted, target).item()\n","    return value\n","\n","def calculate_weights(val1, val2):\n","    '''\n","    In this function we take the number of the background and the forgroud pixels to return the `weights`\n","    for the cross entropy loss values.\n","    '''\n","    count = np.array([val1, val2])\n","    summ = count.sum()\n","    weights = count/summ\n","    weights = 1/weights\n","    summ = weights.sum()\n","    weights = weights/summ\n","    return torch.tensor(weights, dtype=torch.float32)\n","\n","def train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1 , device=torch.device(\"cuda:0\")):\n","    best_metric = -1\n","    best_metric_epoch = -1\n","    save_loss_train = []\n","    save_loss_test = []\n","    save_metric_train = []\n","    save_metric_test = []\n","    train_loader, test_loader = data_in\n","\n","    for epoch in range(max_epochs):\n","        print(\"-\" * 10)\n","        print(f\"epoch {epoch + 1}/{max_epochs}\")\n","        model.train()\n","        train_epoch_loss = 0\n","        train_step = 0\n","        epoch_metric_train = 0\n","        for batch_data in train_loader:\n","\n","            train_step += 1\n","\n","            volume = batch_data[\"vol\"]\n","            label = batch_data[\"seg\"]\n","            label = label != 0\n","            volume, label = (volume.to(device), label.to(device))\n","\n","            optim.zero_grad()\n","            outputs = model(volume)\n","\n","            train_loss = loss(outputs, label)\n","\n","            train_loss.backward()\n","            optim.step()\n","\n","            train_epoch_loss += train_loss.item()\n","            print(\n","                f\"{train_step}/{len(train_loader) // train_loader.batch_size}, \"\n","                f\"Train_loss: {train_loss.item():.4f}\")\n","\n","            train_metric = dice_metric(outputs, label)\n","            epoch_metric_train += train_metric\n","            print(f'Train_dice: {train_metric:.4f}')\n","\n","        print('-'*20)\n","\n","        train_epoch_loss /= train_step\n","        print(f'Epoch_loss: {train_epoch_loss:.4f}')\n","        save_loss_train.append(train_epoch_loss)\n","        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n","\n","        epoch_metric_train /= train_step\n","        print(f'Epoch_metric: {epoch_metric_train:.4f}')\n","\n","        save_metric_train.append(epoch_metric_train)\n","        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n","\n","        if (epoch + 1) % test_interval == 0:\n","\n","            model.eval()\n","            with torch.no_grad():\n","                test_epoch_loss = 0\n","                test_metric = 0\n","                epoch_metric_test = 0\n","                test_step = 0\n","\n","                for test_data in test_loader:\n","\n","                    test_step += 1\n","\n","                    test_volume = test_data[\"vol\"]\n","                    test_label = test_data[\"seg\"]\n","                    test_label = test_label != 0\n","                    test_volume, test_label = (test_volume.to(device), test_label.to(device),)\n","\n","                    test_outputs = model(test_volume)\n","\n","                    test_loss = loss(test_outputs, test_label)\n","                    test_epoch_loss += test_loss.item()\n","                    test_metric = dice_metric(test_outputs, test_label)\n","                    epoch_metric_test += test_metric\n","\n","\n","                test_epoch_loss /= test_step\n","                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n","                save_loss_test.append(test_epoch_loss)\n","                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n","\n","                epoch_metric_test /= test_step\n","                print(f'test_dice_epoch: {epoch_metric_test:.4f}')\n","                save_metric_test.append(epoch_metric_test)\n","                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n","\n","                if epoch_metric_test > best_metric:\n","                    best_metric = epoch_metric_test\n","                    best_metric_epoch = epoch + 1\n","                    torch.save(model.state_dict(), os.path.join(\n","                        model_dir, \"best_metric_model.pth\"))\n","\n","                print(\n","                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\"\n","                    f\"\\nbest mean dice: {best_metric:.4f} \"\n","                    f\"at epoch: {best_metric_epoch}\"\n","                )\n","\n","\n","    print(\n","        f\"train completed, best_metric: {best_metric:.4f} \"\n","        f\"at epoch: {best_metric_epoch}\")\n","\n","\n","def show_patient(data, SLICE_NUMBER=1, train=True, test=False):\n","    \"\"\"\n","    This function is to show one patient from your datasets, so that you can si if the it is okay or you need\n","    to change/delete something.\n","\n","    `data`: this parameter should take the patients from the data loader, which means you need to can the function\n","    prepare first and apply the transforms that you want after that pass it to this function so that you visualize\n","    the patient with the transforms that you want.\n","    `SLICE_NUMBER`: this parameter will take the slice number that you want to display/show\n","    `train`: this parameter is to say that you want to display a patient from the training data (by default it is true)\n","    `test`: this parameter is to say that you want to display a patient from the testing patients.\n","    \"\"\"\n","\n","    check_patient_train, check_patient_test = data\n","\n","    view_train_patient = first(check_patient_train)\n","    view_test_patient = first(check_patient_test)\n","\n","\n","    if train:\n","        plt.figure(\"Visualization Train\", (12, 6))\n","        plt.subplot(1, 2, 1)\n","        plt.title(f\"vol {SLICE_NUMBER}\")\n","        plt.imshow(view_train_patient[\"vol\"][0, 0, :, :, SLICE_NUMBER], cmap=\"gray\")\n","\n","        plt.subplot(1, 2, 2)\n","        plt.title(f\"seg {SLICE_NUMBER}\")\n","        plt.imshow(view_train_patient[\"seg\"][0, 0, :, :, SLICE_NUMBER])\n","        plt.show()\n","\n","    if test:\n","        plt.figure(\"Visualization Test\", (12, 6))\n","        plt.subplot(1, 2, 1)\n","        plt.title(f\"vol {SLICE_NUMBER}\")\n","        plt.imshow(view_test_patient[\"vol\"][0, 0, :, :, SLICE_NUMBER], cmap=\"gray\")\n","\n","        plt.subplot(1, 2, 2)\n","        plt.title(f\"seg {SLICE_NUMBER}\")\n","        plt.imshow(view_test_patient[\"seg\"][0, 0, :, :, SLICE_NUMBER])\n","        plt.show()\n","\n","\n","def calculate_pixels(data):\n","    val = np.zeros((1, 2))\n","\n","    for batch in tqdm(data):\n","        batch_label = batch[\"seg\"] != 0\n","        _, count = np.unique(batch_label, return_counts=True)\n","\n","        if len(count) == 1:\n","            count = np.append(count, 0)\n","        val += count\n","\n","    print('The last values:', val)\n","    return val"]}]}